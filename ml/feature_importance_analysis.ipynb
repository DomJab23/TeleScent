{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a1617f",
   "metadata": {},
   "source": [
    "## 1. Load Trained Models and Data\n",
    "\n",
    "Load the best-performing model (HistGradientBoosting) and the test dataset for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e74d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Load data\n",
    "data_path = Path('data/initial-smell-dataset.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(columns=['sample_id', 'scent_name', 'scent_id'], errors='ignore')\n",
    "y = df['scent_id'].astype(int)\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo purposes, split data again (in practice, use the saved test set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Load best model (HistGradientBoosting)\n",
    "model_path = Path('models/histgradientboosting_model.joblib')\n",
    "best_model = joblib.load(model_path)\n",
    "\n",
    "print(f\"Loaded model from {model_path}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c1c44",
   "metadata": {},
   "source": [
    "## 2. Permutation Importance\n",
    "\n",
    "**What it does**: Shuffles each feature and measures drop in model performance.\n",
    "\n",
    "**Interpretation**: Higher importance = bigger performance drop when feature is shuffled = feature is critical for predictions.\n",
    "\n",
    "**Advantages**: Model-agnostic, easy to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute permutation importance\n",
    "print(\"Computing permutation importance (this may take a minute)...\\n\")\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    best_model, X_test, y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "perm_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': perm_importance.importances_mean,\n",
    "    'Std': perm_importance.importances_std\n",
    "}).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nPermutation Importance Results:\")\n",
    "print(perm_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ebd5e",
   "metadata": {},
   "source": [
    "## 2.1 Visualize Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 features\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "top_n = 15\n",
    "perm_top = perm_df.head(top_n)\n",
    "\n",
    "ax.barh(range(len(perm_top)), perm_top['Importance'],\n",
    "        xerr=perm_top['Std'], alpha=0.8, color='steelblue', edgecolor='black')\n",
    "ax.set_yticks(range(len(perm_top)))\n",
    "ax.set_yticklabels(perm_top['Feature'], fontsize=11)\n",
    "ax.set_xlabel('Drop in Accuracy (Importance)', fontweight='bold', fontsize=12)\n",
    "ax.set_title(f'Top {top_n} Features - Permutation Importance\\n(HistGradientBoosting)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nTotal features analyzed: {len(perm_df)}\")\n",
    "print(f\"Features with positive importance: {(perm_df['Importance'] > 0).sum()}\")\n",
    "print(f\"Features with negative importance: {(perm_df['Importance'] < 0).sum()}\")\n",
    "print(f\"\\nTop 5 Most Important:\")\n",
    "for idx, row in perm_df.head(5).iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Importance']:.6f} (Â±{row['Std']:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d169c",
   "metadata": {},
   "source": [
    "## 3. SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "**What it does**: Uses game theory to fairly distribute model predictions among features.\n",
    "\n",
    "**Interpretation**: SHAP value = contribution of feature to pushing prediction away from base value.\n",
    "\n",
    "**Advantages**: Theoretically sound, provides local interpretability per sample\n",
    "\n",
    "**Note**: Install via `pip install shap` if not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c99b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try importing SHAP\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "    print(\"SHAP library loaded successfully.\\n\")\n",
    "except ImportError:\n",
    "    HAS_SHAP = False\n",
    "    print(\"SHAP not installed. Install via: pip install shap\")\n",
    "    print(\"Continuing with permutation importance only.\\n\")\n",
    "\n",
    "if not HAS_SHAP:\n",
    "    print(\"Skipping SHAP analysis...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d27b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SHAP:\n",
    "    print(\"Computing SHAP values (this may take 2-5 minutes)...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Get the model component from pipeline\n",
    "        model_component = best_model.named_steps['model']\n",
    "        preprocessor = best_model.named_steps['pre']\n",
    "        \n",
    "        # Transform test data\n",
    "        X_test_transformed = preprocessor.transform(X_test)\n",
    "        \n",
    "        # Create SHAP explainer\n",
    "        # Use TreeExplainer for HistGradientBoosting\n",
    "        explainer = shap.TreeExplainer(model_component)\n",
    "        shap_values = explainer.shap_values(X_test_transformed)\n",
    "        \n",
    "        print(\"SHAP values computed successfully.\")\n",
    "        print(f\"SHAP values shape: {np.array(shap_values).shape}\")\n",
    "        \n",
    "        # For multiclass, aggregate across classes\n",
    "        if isinstance(shap_values, list):\n",
    "            # Mean absolute SHAP values across classes\n",
    "            shap_values_abs = np.mean([np.abs(sv) for sv in shap_values], axis=0)\n",
    "        else:\n",
    "            shap_values_abs = np.abs(shap_values)\n",
    "        \n",
    "        # Global feature importance from SHAP\n",
    "        feature_importance_shap = np.mean(shap_values_abs, axis=0)\n",
    "        \n",
    "        # Get feature names from preprocessor\n",
    "        try:\n",
    "            feature_names_transformed = preprocessor.get_feature_names_out().tolist()\n",
    "        except:\n",
    "            feature_names_transformed = [f\"Feature_{i}\" for i in range(X_test_transformed.shape[1])]\n",
    "        \n",
    "        # Create SHAP importance dataframe\n",
    "        shap_df = pd.DataFrame({\n",
    "            'Feature': feature_names_transformed,\n",
    "            'SHAP_Importance': feature_importance_shap\n",
    "        }).sort_values('SHAP_Importance', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        print(\"\\nSHAP Feature Importance (Top 20):\")\n",
    "        print(shap_df.head(20).to_string(index=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing SHAP: {e}\")\n",
    "        HAS_SHAP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e1c4e",
   "metadata": {},
   "source": [
    "## 3.1 SHAP Summary Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b836095",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "067a2a70",
   "metadata": {},
   "source": [
    "## 4. Comparison: Permutation vs SHAP Importance\n",
    "\n",
    "Compare rankings between permutation importance and SHAP to validate feature importance findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SHAP:\n",
    "    # Compare top features from both methods\n",
    "    print(\"\\nComparison of Top Features:\\n\")\n",
    "    print(f\"{'Permutation Top 10':<30} | {'SHAP Top 10':<30}\")\n",
    "    print(\"-\" * 62)\n",
    "    \n",
    "    perm_top10 = perm_df.head(10)['Feature'].values\n",
    "    shap_top10 = shap_df.head(10)['Feature'].values\n",
    "    \n",
    "    for i in range(10):\n",
    "        perm_feat = perm_top10[i] if i < len(perm_top10) else \"\"\n",
    "        shap_feat = shap_top10[i] if i < len(shap_top10) else \"\"\n",
    "        print(f\"{perm_feat:<30} | {shap_feat:<30}\")\n",
    "    \n",
    "    # Find common top features\n",
    "    common_top5 = set(perm_top10[:5]) & set(shap_top10[:5])\n",
    "    print(f\"\\nCommon features in both Top 5: {common_top5}\")\n",
    "else:\n",
    "    print(\"SHAP not available. Showing permutation importance only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a14543",
   "metadata": {},
   "source": [
    "## 5. Feature Importance by Sensor Type\n",
    "\n",
    "Group features by sensor type to understand which **types** of sensors matter most for scent detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sensor groups\n",
    "sensor_groups = {\n",
    "    'Gas Sensors': ['gas_bme', 'srawVoc', 'srawNox', 'NO2', 'ethanol', 'VOC_multichannel', 'COandH2'],\n",
    "    'Environmental': ['temp_C', 'humidity_pct', 'pressure_kPa'],\n",
    "    'Temporal': ['time_s'],\n",
    "    'Metadata': ['trial_number', 'phase']\n",
    "}\n",
    "\n",
    "# Aggregate importance by group\n",
    "group_importance = {}\n",
    "for group, features in sensor_groups.items():\n",
    "    group_features = [f for f in perm_df['Feature'] if f in features]\n",
    "    group_imp = perm_df[perm_df['Feature'].isin(group_features)]['Importance'].sum()\n",
    "    group_importance[group] = group_imp\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "groups = list(group_importance.keys())\n",
    "importances = list(group_importance.values())\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "bars = ax.bar(groups, importances, alpha=0.8, color=colors, edgecolor='black')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Cumulative Importance', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Feature Importance by Sensor Type (Permutation)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Importance by Sensor Type:\")\n",
    "for group, imp in sorted(group_importance.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {group}: {imp:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca7c0c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
