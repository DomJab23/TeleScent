{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ca6b0b",
   "metadata": {},
   "source": [
    "## 1. Load Saved Model\n",
    "\n",
    "Load the best-performing model (HistGradientBoosting) from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Load the trained model\n",
    "models_dir = Path('models')\n",
    "model_path = models_dir / 'histgradientboosting_model.joblib'\n",
    "\n",
    "print(f\"Loading model from {model_path}...\")\n",
    "best_model = joblib.load(model_path)\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Model type: {type(best_model)}\")\n",
    "print(f\"\\nPipeline components:\")\n",
    "for name, step in best_model.named_steps.items():\n",
    "    print(f\"  - {name}: {type(step).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e64de",
   "metadata": {},
   "source": [
    "## 2. Load Reference Data & Scent Mapping\n",
    "\n",
    "Load the original dataset to understand scent labels and create a mapping for interpretable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179462e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data for reference\n",
    "data_path = Path('data/initial-smell-dataset.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Create scent ID to name mapping\n",
    "scent_mapping = df[['scent_id', 'scent_name']].drop_duplicates().sort_values('scent_id')\n",
    "id_to_name = dict(zip(scent_mapping['scent_id'], scent_mapping['scent_name']))\n",
    "name_to_id = {v: k for k, v in id_to_name.items()}\n",
    "\n",
    "print(\"Scent ID to Name Mapping:\")\n",
    "for scent_id, scent_name in id_to_name.items():\n",
    "    print(f\"  {int(scent_id)}: {scent_name}\")\n",
    "\n",
    "# Reference columns for new predictions\n",
    "required_columns = [\n",
    "    'trial_number', 'phase', 'time_s', 'temp_C', 'humidity_pct', 'pressure_kPa',\n",
    "    'gas_bme', 'srawVoc', 'srawNox', 'NO2', 'ethanol', 'VOC_multichannel', 'COandH2'\n",
    "]\n",
    "print(f\"\\nRequired columns for prediction: {required_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b57f46",
   "metadata": {},
   "source": [
    "## 3. Batch Prediction Example\n",
    "\n",
    "Make predictions on a batch of new sensor readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbd1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample new data (simulated sensor readings)\n",
    "# In practice, this would come from your IoT sensors\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'trial_number': [5, 5, 5, 6, 6, 6],\n",
    "    'phase': ['exposure', 'exposure', 'exposure', 'baseline', 'baseline', 'baseline'],\n",
    "    'time_s': [50.0, 75.0, 100.0, 10.0, 20.0, 30.0],\n",
    "    'temp_C': [23.5, 23.5, 23.6, 22.8, 23.0, 23.2],\n",
    "    'humidity_pct': [35.5, 36.0, 36.5, 32.5, 33.0, 33.5],\n",
    "    'pressure_kPa': [100.95, 100.94, 100.93, 100.92, 100.93, 100.94],\n",
    "    'gas_bme': [35.2, 32.5, 31.8, 110.5, 112.0, 113.5],\n",
    "    'srawVoc': [25000, 24900, 24800, 30500, 30600, 30700],\n",
    "    'srawNox': [14700, 14750, 14800, 14600, 14580, 14600],\n",
    "    'NO2': [320, 350, 370, 220, 225, 228],\n",
    "    'ethanol': [480, 520, 550, 370, 375, 380],\n",
    "    'VOC_multichannel': [500, 540, 580, 390, 395, 400],\n",
    "    'COandH2': [1000, 1005, 1010, 850, 855, 860]\n",
    "})\n",
    "\n",
    "print(\"New sensor data (batch of 6 samples):\")\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7115750",
   "metadata": {},
   "source": [
    "### 3.1 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70845986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"Making predictions...\\n\")\n",
    "\n",
    "predicted_ids = best_model.predict(new_data)\n",
    "\n",
    "# Get prediction probabilities (if available)\n",
    "if hasattr(best_model, 'predict_proba'):\n",
    "    try:\n",
    "        # Try to get probabilities via the pipeline\n",
    "        predicted_proba = best_model.predict_proba(new_data)\n",
    "        has_proba = True\n",
    "    except:\n",
    "        predicted_proba = None\n",
    "        has_proba = False\n",
    "else:\n",
    "    predicted_proba = None\n",
    "    has_proba = False\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'Sample': range(1, len(new_data) + 1),\n",
    "    'Phase': new_data['phase'],\n",
    "    'Gas_BME': new_data['gas_bme'],\n",
    "    'Predicted_ID': predicted_ids,\n",
    "    'Predicted_Scent': [id_to_name[pid] for pid in predicted_ids]\n",
    "})\n",
    "\n",
    "# Add confidence if available\n",
    "if has_proba:\n",
    "    max_proba = np.max(predicted_proba, axis=1)\n",
    "    results_df['Confidence'] = max_proba\n",
    "\n",
    "print(\"Prediction Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "if has_proba:\n",
    "    print(f\"\\nAverage confidence: {results_df['Confidence'].mean():.4f}\")\n",
    "    print(f\"Min confidence: {results_df['Confidence'].min():.4f}\")\n",
    "    print(f\"Max confidence: {results_df['Confidence'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24baca7",
   "metadata": {},
   "source": [
    "## 4. Single Sample Prediction (Real-time)\n",
    "\n",
    "Example of predicting a single new sensor reading in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a single sensor reading from IoT device\n",
    "single_reading = pd.DataFrame({\n",
    "    'trial_number': [7],\n",
    "    'phase': ['exposure'],\n",
    "    'time_s': [80.0],\n",
    "    'temp_C': [23.4],\n",
    "    'humidity_pct': [36.2],\n",
    "    'pressure_kPa': [100.94],\n",
    "    'gas_bme': [33.5],\n",
    "    'srawVoc': [24950],\n",
    "    'srawNox': [14780],\n",
    "    'NO2': [340],\n",
    "    'ethanol': [510],\n",
    "    'VOC_multichannel': [550],\n",
    "    'COandH2': [1008]\n",
    "})\n",
    "\n",
    "# Predict\n",
    "predicted_scent_id = best_model.predict(single_reading)[0]\n",
    "predicted_scent_name = id_to_name[predicted_scent_id]\n",
    "\n",
    "# Get confidence if available\n",
    "if has_proba:\n",
    "    proba = best_model.predict_proba(single_reading)[0]\n",
    "    confidence = proba[int(predicted_scent_id - 1)]  # Assuming scent_id starts at 1\n",
    "    print(f\"\\nPredicted Scent: {predicted_scent_name} (ID: {int(predicted_scent_id)})\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    print(f\"\\nProbability distribution across all scents:\")\n",
    "    for scent_id in sorted(id_to_name.keys()):\n",
    "        idx = int(scent_id - 1)\n",
    "        print(f\"  {id_to_name[scent_id]}: {proba[idx]:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nPredicted Scent: {predicted_scent_name} (ID: {int(predicted_scent_id)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891e4c5",
   "metadata": {},
   "source": [
    "## 5. Prediction as JSON (API Ready)\n",
    "\n",
    "Format predictions as JSON for API integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d47264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction response in JSON format (API ready)\n",
    "def format_prediction_json(sensor_data: pd.DataFrame, predictions: np.ndarray, model, id_to_name: dict):\n",
    "    \"\"\"\n",
    "    Format prediction results as JSON for API responses.\n",
    "    \n",
    "    Args:\n",
    "        sensor_data: DataFrame with sensor readings\n",
    "        predictions: Array of predicted scent IDs\n",
    "        model: Trained model pipeline\n",
    "        id_to_name: Dict mapping scent_id to scent_name\n",
    "    \n",
    "    Returns:\n",
    "        JSON-serializable dict\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get probabilities if available\n",
    "    try:\n",
    "        probas = model.predict_proba(sensor_data)\n",
    "        has_proba = True\n",
    "    except:\n",
    "        probas = None\n",
    "        has_proba = False\n",
    "    \n",
    "    for idx, pred_id in enumerate(predictions):\n",
    "        result = {\n",
    "            'sample_index': idx,\n",
    "            'predicted_scent_id': int(pred_id),\n",
    "            'predicted_scent_name': id_to_name[pred_id],\n",
    "            'phase': sensor_data.iloc[idx]['phase'],\n",
    "            'timestamp': sensor_data.iloc[idx]['time_s']\n",
    "        }\n",
    "        \n",
    "        if has_proba:\n",
    "            proba_dict = {}\n",
    "            for scent_id, scent_name in id_to_name.items():\n",
    "                scent_idx = int(scent_id - 1)  # Adjust for 0-indexing\n",
    "                if scent_idx < len(probas[idx]):\n",
    "                    proba_dict[scent_name] = float(probas[idx][scent_idx])\n",
    "            result['probabilities'] = proba_dict\n",
    "            result['confidence'] = float(probas[idx][int(pred_id - 1)])\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return {\n",
    "        'status': 'success',\n",
    "        'model': 'HistGradientBoosting',\n",
    "        'num_predictions': len(predictions),\n",
    "        'predictions': results\n",
    "    }\n",
    "\n",
    "# Format results\n",
    "json_response = format_prediction_json(new_data, predicted_ids, best_model, id_to_name)\n",
    "\n",
    "print(\"JSON Response (API format):\")\n",
    "print(json.dumps(json_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b606e5",
   "metadata": {},
   "source": [
    "## 6. FastAPI Server Helper\n",
    "\n",
    "Code to integrate with FastAPI server for real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example FastAPI integration code (for reference, not to run)\n",
    "fastapi_example = '''\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load model at startup\n",
    "model = joblib.load('models/histgradientboosting_model.joblib')\n",
    "id_to_name = {1: 'apple', 2: 'banana', 3: 'cherry', ...}  # From dataset\n",
    "\n",
    "class SensorReading(BaseModel):\n",
    "    trial_number: int\n",
    "    phase: str\n",
    "    time_s: float\n",
    "    temp_C: float\n",
    "    humidity_pct: float\n",
    "    pressure_kPa: float\n",
    "    gas_bme: float\n",
    "    srawVoc: int\n",
    "    srawNox: int\n",
    "    NO2: int\n",
    "    ethanol: int\n",
    "    VOC_multichannel: int\n",
    "    COandH2: int\n",
    "\n",
    "@app.post('/predict')\n",
    "def predict(reading: SensorReading):\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame([reading.dict()])\n",
    "    \n",
    "    # Make prediction\n",
    "    pred_id = model.predict(df)[0]\n",
    "    proba = model.predict_proba(df)[0]\n",
    "    \n",
    "    return {\n",
    "        'predicted_scent_id': int(pred_id),\n",
    "        'predicted_scent_name': id_to_name[pred_id],\n",
    "        'confidence': float(proba[int(pred_id-1)])\n",
    "    }\n",
    "'''\n",
    "\n",
    "print(\"FastAPI Integration Example:\")\n",
    "print(fastapi_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a7fa6",
   "metadata": {},
   "source": [
    "## 7. Performance Monitoring\n",
    "\n",
    "Monitor model predictions for drift detection and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2185dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Simulate real-time predictions and log them\n",
    "prediction_log = []\n",
    "\n",
    "for i in range(3):\n",
    "    # Simulate new reading\n",
    "    sample = new_data.iloc[i:i+1]\n",
    "    \n",
    "    # Predict\n",
    "    pred_id = best_model.predict(sample)[0]\n",
    "    \n",
    "    # Get confidence if available\n",
    "    if has_proba:\n",
    "        proba = best_model.predict_proba(sample)[0]\n",
    "        confidence = float(proba[int(pred_id - 1)])\n",
    "    else:\n",
    "        confidence = None\n",
    "    \n",
    "    # Log entry\n",
    "    log_entry = {\n",
    "        'timestamp': datetime.datetime.now().isoformat(),\n",
    "        'sample_index': i,\n",
    "        'phase': sample['phase'].values[0],\n",
    "        'gas_bme': float(sample['gas_bme'].values[0]),\n",
    "        'predicted_scent_id': int(pred_id),\n",
    "        'predicted_scent': id_to_name[pred_id],\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    \n",
    "    prediction_log.append(log_entry)\n",
    "    \n",
    "    print(f\"[{log_entry['timestamp']}] Predicted {log_entry['predicted_scent']} \"\n",
    "          f\"(confidence: {confidence:.4f if confidence else 'N/A'})\")\n",
    "\n",
    "# Convert log to DataFrame for analysis\n",
    "log_df = pd.DataFrame(prediction_log)\n",
    "\n",
    "print(\"\\nPrediction Log (first 3 samples):\")\n",
    "print(log_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f95bea",
   "metadata": {},
   "source": [
    "## 8. Best Practices for Deployment\n",
    "\n",
    "Summary of deployment best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_guide = \"\"\"\n",
    "=================================================================\n",
    "BEST PRACTICES FOR SMELL DETECTION MODEL DEPLOYMENT\n",
    "=================================================================\n",
    "\n",
    "1. MODEL VERSIONING\n",
    "   - Save model with version tag: histgradientboosting_v1.0.joblib\n",
    "   - Keep training configuration for reproducibility\n",
    "   - Log model metrics at save time\n",
    "\n",
    "2. INPUT VALIDATION\n",
    "   - Check all required columns are present\n",
    "   - Validate sensor value ranges (e.g., temp_C between -10 and 60Â°C)\n",
    "   - Handle missing values gracefully\n",
    "\n",
    "3. OUTPUT INTERPRETATION\n",
    "   - Always return prediction confidence/probability\n",
    "   - Flag low-confidence predictions (<0.90) for review\n",
    "   - Include timestamp and sensor readings in response\n",
    "\n",
    "4. ERROR HANDLING\n",
    "   - Catch preprocessing errors (e.g., unknown categorical values)\n",
    "   - Return informative error messages\n",
    "   - Log all errors for debugging\n",
    "\n",
    "5. PERFORMANCE MONITORING\n",
    "   - Log all predictions for drift detection\n",
    "   - Monitor confidence score distribution\n",
    "   - Compare with historical performance\n",
    "   - Retrain quarterly or when accuracy drops >2%\n",
    "\n",
    "6. LATENCY OPTIMIZATION\n",
    "   - Batch predictions when possible (<10ms per sample)\n",
    "   - Cache model in memory (don't reload each request)\n",
    "   - Use async endpoints for high-frequency predictions\n",
    "\n",
    "7. DATA FRESHNESS\n",
    "   - Ensure sensor data is recent (<1 second old)\n",
    "   - Handle out-of-order predictions\n",
    "   - Retrain if sensor calibration changes\n",
    "\n",
    "8. SECURITY\n",
    "   - Protect model endpoint with authentication\n",
    "   - Validate input size (max batch: 1000 samples)\n",
    "   - Rate limit requests per user/device\n",
    "\n",
    "=================================================================\n",
    "\"\"\"\n",
    "\n",
    "print(deployment_guide)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
